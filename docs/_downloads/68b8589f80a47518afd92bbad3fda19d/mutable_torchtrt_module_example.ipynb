{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Mutable Torch TensorRT Module\n\nWe are going to demonstrate how we can easily use Mutable Torch TensorRT Module to compile, interact, and modify the TensorRT Graph Module.\n\nCompiling a Torch-TensorRT module is straightforward, but modifying the compiled module can be challenging, especially when it comes to maintaining the state and connection between the PyTorch module and the corresponding Torch-TensorRT module.\nIn Ahead-of-Time (AoT) scenarios, integrating Torch TensorRT with complex pipelines, such as the Hugging Face Stable Diffusion pipeline, becomes even more difficult.\nThe Mutable Torch TensorRT Module is designed to address these challenges, making interaction with the Torch-TensorRT module easier than ever.\n\nIn this tutorial, we are going to walk through\n1. Sample workflow of Mutable Torch TensorRT Module with ResNet 18\n2. Save a Mutable Torch TensorRT Module\n3. Integration with Huggingface pipeline in LoRA use case\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport torch\nimport torch_tensorrt as torch_trt\nimport torchvision.models as models\n\nnp.random.seed(5)\ntorch.manual_seed(5)\ninputs = [torch.rand((1, 3, 224, 224)).to(\"cuda\")]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize the Mutable Torch TensorRT Module with settings.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "settings = {\n    \"use_python\": False,\n    \"enabled_precisions\": {torch.float32},\n    \"make_refittable\": True,\n}\n\nmodel = models.resnet18(pretrained=True).eval().to(\"cuda\")\nmutable_module = torch_trt.MutableTorchTensorRTModule(model, **settings)\n# You can use the mutable module just like the original pytorch module. The compilation happens while you first call the mutable module.\nmutable_module(*inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Make modifications to the mutable module.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Making changes to mutable module can trigger refit or re-compilation. For example, loading a different state_dict and setting new weight values will trigger refit, and adding a module to the model will trigger re-compilation.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model2 = models.resnet18(pretrained=False).eval().to(\"cuda\")\nmutable_module.load_state_dict(model2.state_dict())\n\n\n# Check the output\n# The refit happens while you call the mutable module again.\nexpected_outputs, refitted_outputs = model2(*inputs), mutable_module(*inputs)\nfor expected_output, refitted_output in zip(expected_outputs, refitted_outputs):\n    assert torch.allclose(\n        expected_output, refitted_output, 1e-2, 1e-2\n    ), \"Refit Result is not correct. Refit failed\"\n\nprint(\"Refit successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Saving Mutable Torch TensorRT Module\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Currently, saving is only enabled for C++ runtime, not python runtime.\ntorch_trt.MutableTorchTensorRTModule.save(mutable_module, \"mutable_module.pkl\")\nreload = torch_trt.MutableTorchTensorRTModule.load(\"mutable_module.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Stable Diffusion with Huggingface\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# The LoRA checkpoint is from https://civitai.com/models/12597/moxin\n\nfrom diffusers import DiffusionPipeline\n\nwith torch.no_grad():\n    settings = {\n        \"use_python_runtime\": True,\n        \"enabled_precisions\": {torch.float16},\n        \"debug\": True,\n        \"make_refittable\": True,\n    }\n\n    model_id = \"runwayml/stable-diffusion-v1-5\"\n    device = \"cuda:0\"\n\n    prompt = \"house in forest, shuimobysim, wuchangshuo, best quality\"\n    negative = \"(worst quality:2), (low quality:2), (normal quality:2), lowres, normal quality, out of focus, cloudy, (watermark:2),\"\n\n    pipe = DiffusionPipeline.from_pretrained(\n        model_id, revision=\"fp16\", torch_dtype=torch.float16\n    )\n    pipe.to(device)\n\n    # The only extra line you need\n    pipe.unet = torch_trt.MutableTorchTensorRTModule(pipe.unet, **settings)\n\n    image = pipe(prompt, negative_prompt=negative, num_inference_steps=30).images[0]\n    image.save(\"./without_LoRA_mutable.jpg\")\n\n    # Standard Huggingface LoRA loading procedure\n    pipe.load_lora_weights(\n        \"stablediffusionapi/load_lora_embeddings\",\n        weight_name=\"moxin.safetensors\",\n        adapter_name=\"lora1\",\n    )\n    pipe.set_adapters([\"lora1\"], adapter_weights=[1])\n    pipe.fuse_lora()\n    pipe.unload_lora_weights()\n\n    # Refit triggered\n    image = pipe(prompt, negative_prompt=negative, num_inference_steps=30).images[0]\n    image.save(\"./with_LoRA_mutable.jpg\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}